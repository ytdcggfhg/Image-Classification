# Image Classification

## 1. Image Classification with Noisy Label

### 2025

| Paper                                                        |               Avenue | Link                                                         | Code                                                         |
| ------------------------------------------------------------ | -------------------: | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Directional Label Diffusion Model for Learning from Noisy Labels** <br><sub>Senyu Hou · Gaoxia Jiang · Jia Zhang · Shangrong Yang · Husheng Guo · Yaqing Guo · Wenjian Wang</sub> |            CVPR 2025 | [Paper (CVF PDF)](https://openaccess.thecvf.com/content/CVPR2025/papers/Hou_Directional_Label_Diffusion_Model_for_Learning_from_Noisy_Labels_CVPR_2025_paper.pdf) | [Code](https://github.com/SenyuHou/DLD)                      |
| **Noise-Label Prompt Learning for Vision-Language Models** <br><sub>Bin Pan · Jincheng Yang · Shuhui Wang · Qingming Huang</sub> |            CVPR 2025 | [Paper (CVF PDF)](https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_NLPrompt_Noise-Label_Prompt_Learning_for_Vision-Language_Models_CVPR_2025_paper.pdf) | [Code](![image-20251030181029102](C:\Users\zzhdzj\AppData\Roaming\Typora\typora-user-images\image-20251030181029102.png)) |
| **CA2C: A Prior-Knowledge-Free Approach for Robust Label Noise Learning via Cross-Adaptive Calibration** <br><sub>Ming Sheng · Jiaqi Wang · Qing Yan · Xiaojuan Qi</sub> |            ICCV 2025 | [Paper (ICCV PDF)](https://openaccess.thecvf.com/content/ICCV2025/papers/Sheng_CA2C_A_Prior-Knowledge-Free_Approach_for_Robust_Label_Noise_Learning_via_ICCV_2025_paper.pdf) | [Code](https://github.com/NUST-MachineIntelligence-Laboratory/CA2C) |
| **Joint Asymmetric Loss for Learning with Noisy Labels** <br><sub>Jiahao Wang · Tianlong Chen · Zhangyang Wang</sub> | ICCV 2025 (accepted) | [Paper (ICCV PDF)](https://openaccess.thecvf.com/content/ICCV2025/papers/Wang_Joint_Asymmetric_Loss_for_Learning_with_Noisy_Labels_ICCV_2025_paper.pdf) | [Code](https://github.com/cswjl/joint-asymmetric-loss)       |
| **Optimized Gradient Clipping for Noisy Label Learning** <br><sub>Xichen Ye · Yifan Wu · Weizhong Zhang · Xiaoqiang Li · Yifan Chen · Cheng Jin</sub> |            AAAI 2025 | [Paper (AAAI)](https://ojs.aaai.org/index.php/AAAI/article/view/33025) | [Code](https://github.com/Virusdoll/Optimized-Gradient-Clipping) |
| **Learning with Open-world Noisy Data via Class-independent Margin in Dual Representation Space** <br><sub>X. Yi et al.</sub> |            AAAI 2025 | [Paper (AAAI)](https://ojs.aaai.org/index.php/AAAI/article/view/32673) | [Code](https://github.com/iCAN-SZU/LOND-DRS)                 |
| **Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data** <br><sub>M. Chen et al.</sub> |            AAAI 2025 | [Paper (AAAI)](https://ojs.aaai.org/index.php/AAAI/article/view/34180) | [Code](https://github.com/Aliinton/ConfidenceTracking)       |
| **Instance-dependent Label Distribution Estimation for Learning with Label Noise** <br><sub>Zehui Liao · Shishuai Hu · Yutong Xie · Yong Xia</sub> |            IJCV 2025 | [Paper (Springer)](https://doi.org/10.1007/s11263-024-02299-x) | [Code](https://github.com/Merrical/ILDE)                     |

### 2024

| Paper                                                        |              Avenue | Link                                                         | Code                                         |
| ------------------------------------------------------------ | ------------------: | ------------------------------------------------------------ | -------------------------------------------- |
| **Estimating Noisy Class Posterior with Part-level Labels for Noisy Label Learning** <br><sub>Rui Zhao · Bin Shi · Jianfei Ruan · Tianze Pan · Bo Dong</sub> |           CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Estimating_Noisy_Class_Posterior_with_Part-level_Labels_for_Noisy_Label_CVPR_2024_paper.html) | [Code](https://github.com/RyanZhaoIc/PLM)    |
| **SURE: SUrvey REcipes for building reliable and robust deep networks** <br><sub>Yuting Li · Yingyi Chen · Xuanlong Yu · Dexiong Chen · Xi Shen</sub> |           CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_SURE_SUrvey_REcipes_for_building_reliable_and_robust_deep_networks_CVPR_2024_paper.pdf) | [Code](https://github.com/YutingLi0606/SURE) |
| **Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection** <br><sub>Suyeon Kim · Dongha Lee · SeongKu Kang · Sukang Chae · Sanghwan Jang · Hwanjo Yu</sub> |           CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Learning_Discriminative_Dynamics_with_Label_Corruption_for_Noisy_Label_Detection_CVPR_2024_paper.pdf) | [Code](https://github.com/kimsu55/DynaCor)   |
| **Learning with Structural Labels for Learning with Noisy Labels** <br><sub>Noo-ri Kim · Jin-Seop Lee · Jee-Hyong Lee</sub> |           CVPR 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Learning_with_Structural_Labels_for_Learning_with_Noisy_Labels_CVPR_2024_paper.pdf) | –                                            |
| **Improving Noisy Fine-Grained Datasets using Active Label Cleaning Framework** <br><sub>Avik Pal</sub> | CVPR Workshops 2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024W/VDU/papers/Pal_Improving_Noisy_Fine-Grained_Datasets_using_Active_Label_Cleaning_Framework_CVPRW_2024_paper.pdf) | [Code](https://github.com/PalAvik/alclean)   |

###  2023

| Paper                                                        |       Avenue | Link                                                         | Code                                                        |
| ------------------------------------------------------------ | -----------: | ------------------------------------------------------------ | ----------------------------------------------------------- |
| **DISC: Learning From Noisy Labels via Dynamic Instance-specific Selection and Correction** <br><sub>Y. Li et al.</sub> |    CVPR 2023 | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_DISC_Learning_From_Noisy_Labels_via_Dynamic_Instance-Specific_Selection_and_CVPR_2023_paper.html) | [Code](https://github.com/JackYFL/DISC)                     |
| **Learning From Noisy Labels With Decoupled Meta Label Purifier** <br><sub>Y. Tu et al.</sub> |    CVPR 2023 | [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_Learning_From_Noisy_Labels_With_Decoupled_Meta_Label_Purifier_CVPR_2023_paper.pdf) | [Code](https://github.com/yuanpengtu/DMLP)                  |
| **Fine-Grained Classification With Noisy Labels** <br><sub>Q. Wei et al.</sub> |    CVPR 2023 | [Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Fine-Grained_Classification_With_Noisy_Labels_CVPR_2023_paper.html) | [Code](Fine-Grained Classification with Noisy Labels)       |
| **Twin Contrastive Learning With Noisy Labels** <br><sub>Z. Huang et al.</sub> |    CVPR 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Twin_Contrastive_Learning_With_Noisy_Labels_CVPR_2023_paper.html) | [Code](https://github.com/Hzzone/TCL)                       |
| **RankMatch: Fostering Confidence and Consistency in Learning with Noisy Labels** <br><sub>Z. Zhang et al.</sub> |    ICCV 2023 | [Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.html) | [Code](https://github.com/mai556/RankMatch)                 |
| **When Noisy Labels Meet Long-Tail Dilemmas: A Representation Calibration** <br><sub>M. Zhang et al.</sub> |    ICCV 2023 | [Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.pdf) | –                                                           |
| **Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples** <br><sub>X. Xia et al.</sub> |    ICCV 2023 | [Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf) | –                                                           |
| **Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels** <br><sub>B. Ye et al.</sub> | NeurIPS 2023 | [Paper (NeurIPS)](https://proceedings.neurips.cc/paper_files/paper/2023/file/d191ba4c8923ed8fd8935b7c98658b5f-Paper-Conference.pdf) | [Code](https://github.com/weijiaheng/LRA-Diffusion)         |
| **A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond** <br><sub>X. Xia et al.</sub> |    ICLR 2023 | [Paper (OpenReview)](https://openreview.net/pdf?id=aFzaXRImWE) | [Code](https://github.com/xiaoboxia/T-Matrix-Holistic-View) |

---

## 2. Unsupervised Domain Adaptation (UDA) 

### 2025

| Paper                                                        |     Avenue | Link                                                         | Code                                     |
| ------------------------------------------------------------ | ---------: | ------------------------------------------------------------ | ---------------------------------------- |
| **MODfinity: Unsupervised Domain Adaptation with Multimodal Information Flow Intertwining** <br><sub>S. Liu et al.</sub> |  CVPR 2025 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MODfinity_Unsupervised_Domain_Adaptation_with_Multimodal_Information_Flow_Intertwining_CVPR_2025_paper.html) | –                                        |
| **Concept-Based Unsupervised Domain Adaptation** <br><sub>X. Xu et al.</sub> |  ICML 2025 | [Paper (ICML)](https://icml.cc/virtual/2025/poster/44848)    | [Code](https://github.com/xmed-lab/CUDA) |
| **Counterfactual Knowledge Maintenance for Unsupervised Domain Adaptation** <br><sub>J. Zhang et al.</sub> | IJCAI 2025 | [Paper (IJCAI)](https://www.ijcai.org/proceedings/2025/0165.pdf) | –                                        |

### 2024

| Paper                                                        |    Avenue | Link                                                         | Code                                     |
| ------------------------------------------------------------ | --------: | ------------------------------------------------------------ | ---------------------------------------- |
| **Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation** <br><sub>Z. Du et al.</sub> | CVPR 2024 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2024/html/Du_Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation_CVPR_2024_paper.html) | [Code](https://github.com/TL-UESTC/DAMP) |
| **Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training** <br><sub>A. Reddy et al.</sub> | CVPR 2024 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2024/html/Reddy_Unsupervised_Video_Domain_Adaptation_with_Masked_Pre-Training_and_Collaborative_Self-Training_CVPR_2024_paper.html) | –                                        |
| **Improving Unsupervised Domain Adaptation: A Pseudo-Candidate Set Approach** <br><sub>R. Zhang et al.</sub> | ECCV 2024 | [Paper (ECCV)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04650.pdf) | –                                        |

### 2023

| Paper                                                        |       Avenue | Link                                                         | Code                                           |
| ------------------------------------------------------------ | -----------: | ------------------------------------------------------------ | ---------------------------------------------- |
| **Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation** <br><sub>Y. Xiong et al.</sub> |    ICCV 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html) | [Code](https://github.com/Bostoncake/C-VisDiT) |
| **Homeomorphism Alignment for Unsupervised Domain Adaptation** <br><sub>L. Zhou et al.</sub> |    ICCV 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html) | [Code](https://github.com/buerzlh/HMA)         |
| **Towards Effective Instance Discrimination Contrastive Loss for Unsupervised Domain Adaptation** <br><sub>Y. Zhang et al.</sub> |    ICCV 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html) | –                                              |
| **Mixed Samples as Probes for Unsupervised Model Selection in Domain Adaptation** <br><sub>Y. Wang et al.</sub> | NeurIPS 2023 | [Paper (NeurIPS)](https://proceedings.neurips.cc/paper_files/paper/2023/file/7721f1fea280e9ffae528dc78c732576-Paper-Conference.pdf) | –                                              |

---

## 3. Source-Free UDA (SF-UDA) 

### 2025

| Paper                                                        |       Avenue | Link                                                         | Code                                |
| ------------------------------------------------------------ | -----------: | ------------------------------------------------------------ | ----------------------------------- |
| **Revisiting Source-Free Domain Adaptation: Insights into Representativeness, Generalization, and Variety** <br><sub>R. Zhu et al.</sub> |    CVPR 2025 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Revisiting_Source-Free_Domain_Adaptation_Insights_into_Representativeness_Generalization_and_Variety_CVPR_2025_paper.html) | –                                   |
| **REVISITING SOURCE-FREE DOMAIN ADAPTATION: A NEW PERSPECTIVE VIA UNCERTAINTY CONTROL** <br><sub>G. Xu et al.</sub> |    ICLR 2025 | [Paper (OpenReview)](https://openreview.net/forum?id=nx9Z5Kva96) | –                                   |
| **Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation** <br><sub>S. Tang et al.</sub> | NeurIPS 2025 | [Paper (NeurIPS)](https://neurips.cc/virtual/2025/poster/117343) | –                                   |
| **PROXY DENOISING FOR SOURCE-FREE DOMAIN ADAPTATION** <br><sub>S. Tang et al.</sub> |    ICLR 2025 | [Paper (OpenReview)](https://openreview.net/forum?id=uN6-B-xASL) | [Code](https://x-up-lab.github.io/) |
| **Supportive Negatives Spectral Augmentation for Source-Free Cross-Domain Segmentation** <br><sub>K. Zheng et al.</sub> |    AAAI 2025 | [Paper (AAAI)](https://ojs.aaai.org/index.php/AAAI/article/view/33148) | –                                   |

### 2024

| Paper                                                        |    Avenue | Link                                                         | Code                                              |
| ------------------------------------------------------------ | --------: | ------------------------------------------------------------ | ------------------------------------------------- |
| **Understanding and Improving Source-free Domain Adaptation from a Theoretical Perspective** <br><sub>Y. Mitsuzumi et al.</sub> | CVPR 2024 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2024/html/Mitsuzumi_Understanding_and_Improving_Source-free_Domain_Adaptation_from_a_Theoretical_Perspective_CVPR_2024_paper.html) | [Code](https://github.com/nttcslab/improved_sfda) |
| **Source-Free Domain Adaptation with Frozen Multimodal Foundation Model** <br><sub>S. Tang et al.</sub> | CVPR 2024 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Source-Free_Domain_Adaptation_with_Frozen_Multimodal_Foundation_Model_CVPR_2024_paper.html) | –                                                 |
| **De-Confusing Pseudo-Labels in Source-Free Domain Adaptation** <br><sub>I. Diamant et al.</sub> | ECCV 2024 | [Paper (ECCV)](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10138.pdf) | –                                                 |

### 2023

| Paper                                                        |    Avenue | Link                                                         | Code                                                     |
| ------------------------------------------------------------ | --------: | ------------------------------------------------------------ | -------------------------------------------------------- |
| **When Source-Free Domain Adaptation Meets Learning with Noisy Labels** <br><sub>L. Yi et al.</sub> | ICLR 2023 | [Paper (OpenReview)](https://openreview.net/forum?id=j0-KqL-bEw) | [Code](https://github.com/liyi01827/SFDA_LLN)            |
| **SSDA: Secure Source-Free Domain Adaptation** <br><sub>S. Ahmed et al.</sub> | ICCV 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/ICCV2023/html/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.html) | [Code](https://github.com/ML-Security-Research-LAB/SSDA) |
| **AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation** <br><sub>Y. Zhang et al.</sub> | ICML 2023 | [Paper (PMLR)](https://proceedings.mlr.press/v202/zhang23am.html) | [Code](https://github.com/yfzhang114/AdaNPC)             |
| **Source-Free Video Domain Adaptation With Spatial-Temporal-Historical Consistency Learning** <br><sub>K. Li et al.</sub> | CVPR 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Source-Free_Video_Domain_Adaptation_With_Spatial-Temporal-Historical_Consistency_Learning_CVPR_2023_paper.html) | [Code](https://kailigo.github.io/)                       |

---

## 4. Low-Quality Image Classification

### 2025

| Paper                                                        |    Avenue | Link                                                      | Code |
| ------------------------------------------------------------ | --------: | --------------------------------------------------------- | ---- |
| **QUTE: Quantifying Uncertainty in TinyML models with Early-exit-assisted ensembles** <br><sub>N. G. et al.</sub> | ICML 2025 | [Paper (ICML)](https://icml.cc/virtual/2025/poster/45956) | –    |

### 2024

| Paper                                                        |              Avenue | Link                                                         | Code                                         |
| ------------------------------------------------------------ | ------------------: | ------------------------------------------------------------ | -------------------------------------------- |
| **Improving robustness to corruptions with multiplicative weight perturbations** <br><sub>T. Trinh et al.</sub> |        NeurIPS 2024 | [Paper (NeurIPS)](https://proceedings.neurips.cc/paper_files/paper/2024/file/3e9412a9c1d93810ef3ef7825115016b-Paper-Conference.pdf) | [Code](https://github.com/trungtrinh44/DAMP) |
| **Noisy Label Processing for Classification: A Survey** <br><sub>Various</sub> | arXiv 2024 (survey) | [Survey (arXiv)](https://arxiv.org/pdf/2404.04159)           | –                                            |
| **Learning Quality Labels for Robust Image Classification** <br><sub>X. Wang et al.</sub> |           WACV 2024 | [Paper (WACV PDF)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Learning_Quality_Labels_for_Robust_Image_Classification_WACV_2024_paper.pdf) | –                                            |

### 2023

| Paper                                                        |                                     Avenue | Link                                                         | Code                                                 |
| ------------------------------------------------------------ | -----------------------------------------: | ------------------------------------------------------------ | ---------------------------------------------------- |
| **GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image** <br><sub>Z. Wang et al.</sub> |     NeurIPS 2023 (Datasets and Benchmarks) | [Paper (NeurIPS)](https://proceedings.neurips.cc/paper_files/paper/2023/file/f4d4a021f9051a6c18183b059117e8b5-Paper-Datasets_and_Benchmarks.pdf) | [Code](https://github.com/GenImage-Dataset/GenImage) |
| **MetaMix: Towards Corruption-Robust Continual Learning With Temporally Self-Adaptive Data Transformation** <br><sub>Z. Wang et al.</sub> |                                  CVPR 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_MetaMix_Towards_Corruption-Robust_Continual_Learning_With_Temporally_Self-Adaptive_Data_Transformation_CVPR_2023_paper.html) | [Code](https://yjzhux.github.io/)                    |
| **FFT-based Selection and Optimization of Statistics for Robust Recognition of Severely Corrupted Images** <br><sub>Y. Golan et al.</sub> |                                  ICCV 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/ICCV2023/papers/Golan_FFT-based_Selection_and_Optimization_of_Statistics_for_Robust_Recognition_of_ICCV_2023_paper.pdf) | [Code](https://github.com/YoniGolan/FROST)           |
| **Confidence-based Reliable Learning under Dual Noises**  <br><sub>P. Cui et al.</sub> | arXiv / conference submissions (2022–2023) | [Paper (PDF)](https://thudzj.github.io/dualn/paper.pdf)      | –                                                    |
| **Label Noise Transition Matrix Estimation for Tasks with Lower-quality Features** <br><sub>Z. Zhu et al.</sub> |                        AISTATS / PMLR 2022 | [Paper (MLR PDF)](https://proceedings.mlr.press/v162/zhu22k/zhu22k.pdf) | –                                                    |

# Fine-Grained Image Classification 

## 1. Fine-Grained Image Classification with Noisy Label

| Paper                                                        |                         Avenue | Link                                                         | Code                                              |
| ------------------------------------------------------------ | -----------------------------: | ------------------------------------------------------------ | ------------------------------------------------- |
| **Fine-Grained Classification with Noisy Labels** <br><sub>Q. Wei et al.</sub> |                      CVPR 2023 | [Paper (CVF)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Fine-Grained_Classification_With_Noisy_Labels_CVPR_2023_paper.pdf) | [Code](https://github.com/wei-q/SNSCL)            |
| **Noisy Ostracods: A Fine-Grained, Imbalanced Real-World Dataset for Benchmarking Robust Machine Learning and Label Correction Methods** <br><sub>B. S. S. G. T. Dassanayake et al.</sub> |                   NeurIPS 2024 | [Paper (OpenReview)](https://openreview.net/forum?id=MUnPBKBaCY) | [Code](https://github.com/Bogasky/NoisyOstracods) |
| **Efficient Vocabulary-Free Fine-Grained Visual Recognition in the Age of Multimodal LLMs** <br><sub>V. L. et al.</sub> |                     arXiv 2025 | [Paper (arXiv)](https://arxiv.org/abs/2505.01064)            | –                                                 |
| **Robust Fine-Grained Visual Recognition With Neighbor-Attention Label Correction** <br><sub>H. Zhang et al.</sub> | IEEE Trans. Image Process 2024 | [Paper (IEEE)](https://ieeexplore.ieee.org/abstract/document/10485225) | –                                                 |



## 2. UDA for Fine-Grained Image Classification

| Paper                                                        |               Avenue | Link                                                         | Code                                                       |
| ------------------------------------------------------------ | -------------------: | ------------------------------------------------------------ | ---------------------------------------------------------- |
| **microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification** <br><sub>S. P. et al.</sub> |           arXiv 2025 | [Paper (arXiv)](https://arxiv.org/abs/2510.02270)            | [Code](https://github.com/sathiiii/microCLIP)              |
| **Domain Adaptive Transfer Learning on Visual Attention Aware Data Augmentation for Fine-Grained Visual Categorization** <br><sub>S. M. S. I. et al.</sub> |           arXiv 2020 | [Paper (arXiv)](https://arxiv.org/abs/2010.03071)            | –                                                          |
| **An Adversarial Domain Adaptation Network for Cross-Domain Fine-Grained Recognition** <br><sub>Y. Wang et al.</sub> |            WACV 2020 | [Paper (CVF)](https://openaccess.thecvf.com/content_WACV_2020/papers/Wang_An_Adversarial_Domain_Adaptation_Network_for_Cross-Domain_Fine-Grained_Recognition_WACV_2020_paper.pdf) | [Code](https://yimuwang96.github.io/ DA-Retail/index.html) |
| **Striking a Balance in Unsupervised Fine-Grained Domain Adaptation Using Adversarial Learning** <br><sub>S. Rakshit et al.</sub> | WACV 2020 (Workshop) | [Paper (ResearchGate)](https://www.researchgate.net/publication/343753928_Striking_a_Balance_in_Unsupervised_Fine-Grained_Domain_Adaptation_Using_Adversarial_Learning) | –                                                          |



## 3. SF-UDA for Fine-Grained Image Classification

| Paper                                                        |            Avenue | Link                                                         | Code                                           |
| ------------------------------------------------------------ | ----------------: | ------------------------------------------------------------ | ---------------------------------------------- |
| **ReCLIP: Refine Contrastive Language Image Pre-Training With Source Free Domain Adaptation** <br><sub>T. Hu et al.</sub> |         WACV 2024 | [Paper (CVF)](https://openaccess.thecvf.com/content/WACV2024/papers/Hu_ReCLIP_Refine_Contrastive_Language_Image_Pre-Training_With_Source_Free_Domain_WACV_2024_paper.pdf) | [Code](https://github.com/HFA-Research/ReCLIP) |
| **EIANet: A novel domain adaptation approach to maximize class distinction with neural collapse principles** <br><sub>Z. Pan et al.</sub> |         BMVC 2024 | [Paper (BMVC)](https://arxiv.org/abs/2407.16189)             | [Code](https://github.com/zichengpan/EIANet)   |
| **Real-World Coarse to Fine-Grained Source-Free Multidomain Adaptation** <br><sub>P. R. et al.</sub> | ResearchGate 2024 | [Paper (ResearchGate)](https://www.researchgate.net/publication/386458026_Real-World_Coarse_to_Fine-Grained_Source-Free_Multidomain_Adaptation) | –                                              |
| **Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score** <br><sub>T. Yu et al.</sub> |        arXiv 2025 | [Paper (arXiv)](https://arxiv.org/abs/2507.09615)            | –                                              |



## 4. Low-Quality Fine-Grained Image Classification

| Paper                                                        |                  Avenue | Link                                                         | Code |
| ------------------------------------------------------------ | ----------------------: | ------------------------------------------------------------ | ---- |
| **How Quality Affects Deep Neural Networks in Fine-Grained Image Classification** <br><sub>J. Smith et al.</sub> |              arXiv 2024 | [Paper (arXiv)](https://arxiv.org/abs/2405.05742)            | –    |
| **Degraded Image Classification using Knowledge Distillation and Robust Data Augmentations** <br><sub>T. Yamane et al.</sub> | IEICE Transactions 2024 | [Paper (ResearchGate)](https://www.researchgate.net/publication/382574685_Degraded_image_classification_using_knowledge_distillation_and_robust_data_augmentations) | –    |
| **Convolutional Low-Resolution Fine-Grained Classification** <br><sub>S. E. H. El-Seoud et al.</sub> |              IJCSI 2017 | [Paper (ResearchGate)](https://www.researchgate.net/publication/315116436_Convolutional_Low-Resolution_Fine-Grained_Classification) | –    |
| **Quantized Convolutional Neural Networks Robustness under Perturbation** <br><sub>C. D. et al.</sub> |      F1000Research 2025 | [Paper (F1000)](https://f1000research.com/articles/14-419)   | –    |
